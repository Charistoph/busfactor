{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect Scooters to Graph (and Warehouses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What you should have by now:\n",
    "\n",
    "- nodes_final.csv - Contains all nodes of the city graph. The city graph is big enough to enclose all warehouses in the city\n",
    "- edges_final.csv - The edges connecting the nodes including columns like 'gh', 'lat/lng', 'type', 'maxspeed', 'dist', 'realspeed',  'drive_time'\n",
    "- a dicts folder inside the output (currently named new sol) folder. These dictionaries contain the drive times from every node to every other node (at the moment 30000^2 ~= 10^8 key value pairs)\n",
    "- where_nodes_dict.csv (inside dict folder) - This dictionary contains a complete mapping of which node and its corresponding drive times is saved in which dict file.\n",
    "\n",
    "## THESE FILES ARE REQUIRED INPUTS FOR THIS NOTEBOOK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VRP\n",
    "from __future__ import print_function\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import overpy\n",
    "import pprint\n",
    "import geojson\n",
    "import time\n",
    "import pickle\n",
    "from h3 import h3\n",
    "from keplergl import KeplerGl\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "# VRP\n",
    "from ortools.constraint_solver import routing_enums_pb2\n",
    "from ortools.constraint_solver import pywrapcp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_create_folder(folder_name: str):\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "    return None\n",
    "\n",
    "\n",
    "def aggregate_df(total: pd.DataFrame, tmp: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Concats a new dataframe to an existing base dataframe.\n",
    "    Parameters\n",
    "    ----------\n",
    "    total - base dataframe\n",
    "    tmp - new dataframe\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    If the length of new dataframe == 0: returns base dataframe.\n",
    "    If the length of new dataframe > 0 and the length of base dataframe == 0: returns the new dataframe\n",
    "    If the length of new dataframe > 0 and the length of base dataframe > 0:\n",
    "    returns base dataframe with the new dataframe concated to the end of the base dataframe.\n",
    "    \"\"\"\n",
    "    if len(tmp) > 0:\n",
    "        if len(total) > 0:\n",
    "            total = pd.concat([total, tmp], sort=False)\n",
    "        else:\n",
    "            total = tmp\n",
    "    return total\n",
    "\n",
    "\n",
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points\n",
    "    on the earth (specified in decimal degrees)\n",
    "    \"\"\"\n",
    "    # convert decimal degrees to radians\n",
    "    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n",
    "    # haversine formula\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = (np.sin(dlat / 2) ** 2\n",
    "         + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2) ** 2)\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    km = 6367 * c\n",
    "    return km * 1000\n",
    "\n",
    "def apply_hav(x):\n",
    "    try:\n",
    "        return haversine(float(x.start_lng), float(x.start_lat), \n",
    "                         float(x.end_lng), float(x.end_lat))\n",
    "    except:\n",
    "        print(x.start_lng, x.start_lat, x.end_lng, x.end_lat)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_json_name = 'routing_inputs_smol.json'\n",
    "\n",
    "inputs_folder = 'inputs'\n",
    "output_folder = 'new_sol'\n",
    "dict_store = 'dicts'\n",
    "plots_path = os.path.join(output_folder, 'plots')\n",
    "dicts_path = os.path.join(output_folder, dict_store)\n",
    "try_create_folder(output_folder)\n",
    "try_create_folder(plots_path)\n",
    "try_create_folder(dicts_path)\n",
    "\n",
    "wh_df = pd.DataFrame([\n",
    "    ['wh0', 52.436, 13.376],\n",
    "    ['wh1', 52.561, 13.475]\n",
    "], columns=['name', 'lat', 'lng'])\n",
    "\n",
    "city_lat, city_lng = 52.52, 13.40\n",
    "len_half_window = 75\n",
    "reasonable_radius_margin = 0.05\n",
    "\n",
    "realistic_speed = {\n",
    "    3: 3,\n",
    "    5: 5,\n",
    "    6: 6,\n",
    "    7: 7,\n",
    "    10: 8,\n",
    "    15: 13,\n",
    "    17: 15,\n",
    "    20: 18,\n",
    "    30: 25,\n",
    "    40: 33,\n",
    "    50: 37,\n",
    "    60: 54,\n",
    "    70: 62,\n",
    "    80: 71,\n",
    "    100: 90,\n",
    "    130: 120\n",
    "}\n",
    "\n",
    "# Berlin Bounding Box\n",
    "# NW 52.6716, 13.0875\n",
    "# SO 52.3923, 13.6858"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Scooters and Drivers from routing_inputs.json mimicking an API call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>start_location</th>\n",
       "      <th>end_location</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>capacity</th>\n",
       "      <th>type</th>\n",
       "      <th>start_lat</th>\n",
       "      <th>start_lng</th>\n",
       "      <th>end_lat</th>\n",
       "      <th>end_lng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>wh0</td>\n",
       "      <td>wh0</td>\n",
       "      <td>2019-12-24 12:00:00</td>\n",
       "      <td>2019-12-24 18:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>van</td>\n",
       "      <td>52.436</td>\n",
       "      <td>13.376</td>\n",
       "      <td>52.436</td>\n",
       "      <td>13.376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>wh0</td>\n",
       "      <td>wh0</td>\n",
       "      <td>2019-12-24 14:00:00</td>\n",
       "      <td>2019-12-24 18:00:00</td>\n",
       "      <td>10</td>\n",
       "      <td>bike</td>\n",
       "      <td>52.436</td>\n",
       "      <td>13.376</td>\n",
       "      <td>52.436</td>\n",
       "      <td>13.376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>wh0</td>\n",
       "      <td>wh0</td>\n",
       "      <td>2019-12-24 14:00:00</td>\n",
       "      <td>2019-12-24 18:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>van</td>\n",
       "      <td>52.436</td>\n",
       "      <td>13.376</td>\n",
       "      <td>52.436</td>\n",
       "      <td>13.376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id start_location end_location           start_time             end_time  \\\n",
       "0  0            wh0          wh0  2019-12-24 12:00:00  2019-12-24 18:00:00   \n",
       "1  1            wh0          wh0  2019-12-24 14:00:00  2019-12-24 18:00:00   \n",
       "2  2            wh0          wh0  2019-12-24 14:00:00  2019-12-24 18:00:00   \n",
       "\n",
       "  capacity  type  start_lat  start_lng  end_lat  end_lng  \n",
       "0        3   van     52.436     13.376   52.436   13.376  \n",
       "1       10  bike     52.436     13.376   52.436   13.376  \n",
       "2        4   van     52.436     13.376   52.436   13.376  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lng</th>\n",
       "      <th>lat</th>\n",
       "      <th>scooter_id</th>\n",
       "      <th>gh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>13.3953</td>\n",
       "      <td>52.5243</td>\n",
       "      <td>69aae7bd</td>\n",
       "      <td>8a1f1d489c8ffff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>13.3655</td>\n",
       "      <td>52.503</td>\n",
       "      <td>eb88cbe1</td>\n",
       "      <td>8a1f1d48a387fff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>13.3512</td>\n",
       "      <td>52.5142</td>\n",
       "      <td>da50c033</td>\n",
       "      <td>8a1f1d48a91ffff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>13.392</td>\n",
       "      <td>52.53</td>\n",
       "      <td>c326c7af</td>\n",
       "      <td>8a1f1d489d37fff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>13.2818</td>\n",
       "      <td>52.5894</td>\n",
       "      <td>bdceae74</td>\n",
       "      <td>8a1f1d4a1d8ffff</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       lng      lat scooter_id               gh\n",
       "0  13.3953  52.5243   69aae7bd  8a1f1d489c8ffff\n",
       "1  13.3655   52.503   eb88cbe1  8a1f1d48a387fff\n",
       "2  13.3512  52.5142   da50c033  8a1f1d48a91ffff\n",
       "3   13.392    52.53   c326c7af  8a1f1d489d37fff\n",
       "4  13.2818  52.5894   bdceae74  8a1f1d4a1d8ffff"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(drivers): 3\n",
      "len(scooters): 19\n"
     ]
    }
   ],
   "source": [
    "# # create scooters dict\n",
    "# solutions_folder = '../antani_viz/data'\n",
    "# with open(os.path.join(solutions_folder, 'sol_grandC.json')) as f:\n",
    "#     d = json.load(f)\n",
    "# routes = pd.DataFrame(d['path']).transpose().sort_values(\"agent\").set_index(\"agent\")\n",
    "# scooters = pd.DataFrame(d['spot']).transpose().reset_index(drop=True)\n",
    "# scooters = scooters[['x', 'y', 'name']].reset_index(drop=True).rename(\n",
    "#     columns={'x': 'lng', 'y': 'lat', 'name': 'scooter_id'})\n",
    "# scooters = scooters.assign(\n",
    "#     scooter_id = scooters['scooter_id'].apply(lambda x: x[:8]))\n",
    "# scooters = scooters.assign(\n",
    "#     idx = scooters['scooter_id'].apply(lambda x: random.randint(100000,999999)))\n",
    "# scooters = scooters.set_index(\"idx\")\n",
    "# scooters.transpose().to_json(\"tmp.json\")\n",
    "\n",
    "with open(os.path.join(inputs_folder, input_json_name)) as f:\n",
    "    d = json.load(f)\n",
    "drivers = pd.DataFrame(d['drivers']).transpose().sort_values(\"id\").reset_index(drop=True)\n",
    "scooters = pd.DataFrame(d['scooters']).transpose().reset_index(drop=True)\n",
    "# get gh for each scooter\n",
    "scooters = scooters.assign(gh = scooters.apply(\n",
    "    lambda x: h3.geo_to_h3(float(x.lat), float(x.lng), 10), axis=1))\n",
    "\n",
    "wh_dict = wh_df.set_index('name').transpose().to_dict()\n",
    "drivers = drivers.assign(\n",
    "    start_lat = drivers['start_location'].apply(lambda x: wh_dict[x]['lat']))\n",
    "drivers = drivers.assign(\n",
    "    start_lng = drivers['start_location'].apply(lambda x: wh_dict[x]['lng']))\n",
    "drivers = drivers.assign(\n",
    "    end_lat = drivers['end_location'].apply(lambda x: wh_dict[x]['lat']))\n",
    "drivers = drivers.assign(\n",
    "    end_lng = drivers['end_location'].apply(lambda x: wh_dict[x]['lng']))\n",
    "display(drivers.head())\n",
    "display(scooters.head())\n",
    "print('len(drivers): %i' % len(drivers))\n",
    "print('len(scooters): %i' % len(scooters))\n",
    "drivers.to_csv(os.path.join(output_folder, 'drivers.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect scooter locations with graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reasonable_window(city_lat, city_lng, len_half_window=75, verbose=False):\n",
    "    \"\"\"\n",
    "    get reasonable window sizes\n",
    "    using f.e. 75 gives you a 150 x 150 m window    \n",
    "    \"\"\"\n",
    "    for i in range(100):\n",
    "        dist = haversine(city_lat, city_lng, city_lat, city_lng + 0.0001 * i)\n",
    "        if dist > len_half_window:\n",
    "            break\n",
    "    stretch_lat = round(0.0001 * i, 4)\n",
    "\n",
    "    for i in range(100):\n",
    "        dist = haversine(city_lat, city_lng, city_lat + 0.0001 * i, city_lng)\n",
    "        if dist > len_half_window:\n",
    "            break\n",
    "    stretch_lng = round(0.0001 * i, 4)\n",
    "\n",
    "    if verbose:\n",
    "        print(stretch_lat, stretch_lng)\n",
    "\n",
    "    return stretch_lat, stretch_lng\n",
    "\n",
    "\n",
    "def window_node_finder(nodes, lat, lng, stretch_lat=0.0001,\n",
    "                          stretch_lng=0.0001, multiplier=1):\n",
    "    \"\"\"\n",
    "    returns idx of nodes that are within a search window given by\n",
    "    stretch_lat, stretch_lng, multiplier\n",
    "    \"\"\"\n",
    "    return nodes[\n",
    "        (nodes['lat'] > lat - stretch_lat * multiplier) &\n",
    "        (nodes['lat'] < lat + stretch_lat * multiplier) &\n",
    "        (nodes['lng'] > lng - stretch_lng * multiplier) &\n",
    "        (nodes['lng'] < lng + stretch_lng * multiplier)]\n",
    "\n",
    "\n",
    "def search_closest_nodes_window(nodes, df, df_id_col='scooter_id',\n",
    "                                stretch_lat=0.0001, stretch_lng=0.0001):\n",
    "    \"\"\"\n",
    "    iterate over scooter rows and find all nodes within a small window\n",
    "    if nothing is returned, try a slightly bigger window\n",
    "    if still nothing is returned, save for later (gh matching)\n",
    "    \"\"\"\n",
    "    raw_matches = []\n",
    "    no_match = []\n",
    "    print('search_closest_nodes_window: start window matching')\n",
    "    start_time = time.time()\n",
    "    for idx, row in df.iterrows():\n",
    "        # get node idx within window\n",
    "        idxs = window_node_finder(\n",
    "            nodes, row.lat, row.lng, stretch_lat,\n",
    "            stretch_lng, 1)['id'].values\n",
    "        # save all indexes in raw_matches\n",
    "        for idx in idxs:\n",
    "            raw_matches.append([row[df_id_col], idx])\n",
    "        # if no indexes were found, try again for a bigger window\n",
    "        if len(idxs) == 0:\n",
    "            # get node idx within bigger window (diameter 5x bigger)\n",
    "            idxs = window_node_finder(\n",
    "                nodes, row.lat, row.lng, stretch_lat,\n",
    "                stretch_lng, 5)['id'].values\n",
    "            # save all indexes in raw_matches\n",
    "            for idx in idxs:\n",
    "                raw_matches.append([row[df_id_col], idx])\n",
    "            # if still no indexes found, append node id to no_match column\n",
    "            if len(idxs) == 0:\n",
    "                no_match.append(row[df_id_col])\n",
    "\n",
    "    print('search_closest_nodes_window: window matching finished after %0.2f sec' % (\n",
    "            time.time() - start_time))\n",
    "    print(\"search_closest_nodes_window: %i matches generated for %i df\" % (\n",
    "        len(raw_matches), len(df)))\n",
    "    print('search_closest_nodes_window: len(no_match): %i' % len(no_match))\n",
    "\n",
    "    return raw_matches, no_match\n",
    "\n",
    "\n",
    "def put_dict(d, keys, item):\n",
    "    if \".\" in keys:\n",
    "        key, rest = keys.split(\".\", 1)\n",
    "        if key not in d:\n",
    "            d[key] = {}\n",
    "        put_dict(d[key], rest, item)\n",
    "    else:\n",
    "        d[keys] = item\n",
    "\n",
    "\n",
    "def get_dict(d, keys):\n",
    "    if \".\" in keys:\n",
    "        key, rest = keys.split(\".\", 1)\n",
    "        return get_dict(d[key], rest)\n",
    "    else:\n",
    "        return d[keys]\n",
    "\n",
    "\n",
    "def search_closest_nodes_dict(node_dict, df, df_id_col='scooter_id',\n",
    "                              no_match=[]):\n",
    "    \"\"\"\n",
    "    generate matches by retrieving the closest geohashes for each scooter\n",
    "    \"\"\"\n",
    "    raw_matches = []\n",
    "    direct_hits = 0\n",
    "    num_breaks = 0\n",
    "    break_num = 50\n",
    "    print('search_closest_nodes_dict: start gh dict matching calculation')\n",
    "    start_time = time.time()\n",
    "\n",
    "    # if no_match array is supplied, \n",
    "    # filter out rows in df which don't match an id from no_match\n",
    "    if len(no_match) > 0:\n",
    "        df = df[df[df_id_col].isin(no_match)]\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        gh = list(row['gh'])\n",
    "        count = 0\n",
    "\n",
    "        # iterate through geohash entries iteratively removing \n",
    "        # the last item at each iteration\n",
    "        for i in range(len(gh)):\n",
    "            try:\n",
    "                # print(row['gh'], get_dict(node_dict, '.'.join(gh[:-i])))\n",
    "                # iteratively removing the last item at each iteration\n",
    "                res = get_dict(node_dict, '.'.join(gh[:-i]))\n",
    "\n",
    "                # in case of an exact match, append id that was retrieved\n",
    "                # from node_dict to the matches array\n",
    "                if type(res) == int:\n",
    "                    direct_hits += 1\n",
    "                    print(\"direct hit\")\n",
    "                    # print(res)\n",
    "                    raw_matches.append([row[df_id_col], res])\n",
    "                    break\n",
    "                # in case of a partial match, append the 10 first ids that were \n",
    "                # retrieved from node_dict to the matches array\n",
    "                elif type(res) == dict:\n",
    "                    arr = str(res).split(\"': \")\n",
    "                    for item in arr:\n",
    "                        if len(item) > 7:\n",
    "                            count += 1\n",
    "                            if count > break_num:\n",
    "                                num_breaks += 1\n",
    "                                break\n",
    "                            # print(int(item.split(\"}\")[0]))\n",
    "                            raw_matches.append([row[df_id_col],\n",
    "                                                int(item.split(\"}\")[0])])\n",
    "                else:\n",
    "                    assert 0 == 1, \"ERROR\"\n",
    "                if count > 10:\n",
    "                    num_breaks += 1\n",
    "                    break\n",
    "\n",
    "            except KeyError as e:\n",
    "                None\n",
    "\n",
    "    print('search_closest_nodes_dict: gh dict matching finished after %0.2f sec' % (\n",
    "            time.time() - start_time))\n",
    "    print(\"search_closest_nodes_dict: %i matches generated for %i df\" % (\n",
    "        len(raw_matches), len(df[df[df_id_col].isin(no_match)])))\n",
    "    print('search_closest_nodes_dict: direct_hits: %i, num_breaks: %i, len(df): %i' % (\n",
    "        direct_hits, num_breaks, len(df[df[df_id_col].isin(no_match)])))\n",
    "\n",
    "    return raw_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search_closest_nodes_window: start window matching\n",
      "search_closest_nodes_window: window matching finished after 0.06 sec\n",
      "search_closest_nodes_window: 121 matches generated for 19 df\n",
      "search_closest_nodes_window: len(no_match): 1\n",
      "search_closest_nodes_dict: start gh dict matching calculation\n",
      "search_closest_nodes_dict: gh dict matching finished after 0.00 sec\n",
      "search_closest_nodes_dict: 50 matches generated for 1 df\n",
      "search_closest_nodes_dict: direct_hits: 0, num_breaks: 2, len(df): 1\n",
      "total matches: 171\n"
     ]
    }
   ],
   "source": [
    "edges = pd.read_csv(os.path.join(output_folder, \"edges_final.csv\"), index_col=0)\n",
    "nodes = pd.read_csv(os.path.join(output_folder, \"nodes_final.csv\"), index_col=0)\n",
    "\n",
    "\n",
    "stretch_lat, stretch_lng = get_reasonable_window(\n",
    "    len_half_window, True)\n",
    "\n",
    "raw_matches_window, no_match = search_closest_nodes_window(\n",
    "    nodes, scooters, 'scooter_id', stretch_lat, stretch_lng)\n",
    "\n",
    "\n",
    "# recursively create a nested dictionary of all geohashes (with node ids as values)\n",
    "node_dict = dict()\n",
    "# put all nodes into a dict\n",
    "for idx, row in nodes.iterrows():\n",
    "    put_dict(node_dict, '.'.join(list(row['gh'])), row['id'])\n",
    "# test with:\n",
    "#     print(row['gh'], get_dict(node_dict, '.'.join(list(row['gh']))))\n",
    "# print dict\n",
    "# pprint.pprint(node_dict)\n",
    "\n",
    "\n",
    "raw_matches = search_closest_nodes_dict(\n",
    "    node_dict, scooters, 'scooter_id', no_match)\n",
    "\n",
    "\n",
    "# join window matches and geohash matches together\n",
    "len_raw_matches = len(raw_matches)\n",
    "len_raw_matches_window = len(raw_matches_window)\n",
    "raw_matches.extend(raw_matches_window)\n",
    "assert len(raw_matches) == len_raw_matches + len_raw_matches_window\n",
    "print(\"total matches: %i\" % len(raw_matches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean matching distance: 81.39\n",
      "median matching distance: 24.24\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "matches_link = pd.DataFrame(raw_matches, columns=['scooter_id', 'node_id'])\n",
    "\n",
    "# join scooter df with matches\n",
    "scooter_matched = matches_link.join(scooters.set_index('scooter_id'), on='scooter_id')\n",
    "assert len(scooter_matched) == len(matches_link)\n",
    "\n",
    "# join nodes df with matches\n",
    "matched = scooter_matched.join(nodes.drop(\n",
    "    columns=['gh']).set_index('id'), on='node_id', rsuffix='_node')\n",
    "assert len(scooter_matched) == len(matched)\n",
    "\n",
    "# calculate distances between scooters and nodes\n",
    "dist = matched.rename(\n",
    "    columns={'lng': 'start_lng', 'lat': 'start_lat', \n",
    "             'lat_node': 'end_lat', 'lng_node': 'end_lng'}).apply(\n",
    "    lambda x: apply_hav(x), axis=1)\n",
    "matched = matched.assign(dist = dist)\n",
    "matched = matched.sort_values('dist')\n",
    "scooter_nodes = matched.groupby('scooter_id').first().reset_index()\n",
    "\n",
    "# check that scooters are not unreasonable far away from nodes\n",
    "# assert sel_nodes['dist'].max() < 200\n",
    "\n",
    "print(\"mean matching distance: %0.2f\\nmedian matching distance: %0.2f\" % (\n",
    "    np.mean(scooter_nodes.dist.values),\n",
    "    np.median(scooter_nodes.dist.values)))\n",
    "plt.title('Histogram of Matching Distances (capped at 200)')\n",
    "plt.hist(scooter_nodes.dist.values[scooter_nodes.dist.values<200], bins=100)\n",
    "plt.ylabel('counts')\n",
    "plt.xlabel('distance [m]')\n",
    "plt.savefig(os.path.join(plots_path, 'matching_distances.png'), dpi=400)\n",
    "\n",
    "# map_1 = KeplerGl(height=500, data={\n",
    "#     'data_1': sel_nodes[sel_nodes.dist.values<200].round({'dist': 0}),\n",
    "#     'nodes': nodes\n",
    "# }) # , config=config\n",
    "# map_1\n",
    "\n",
    "# map_1 = KeplerGl(height=500, data={\n",
    "#     'data_1': sel_nodes.round({'dist': 0}),\n",
    "#     'nodes': nodes\n",
    "# }) # , config=config\n",
    "# map_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match Warehouses to Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search_closest_nodes_window: start window matching\n",
      "search_closest_nodes_window: window matching finished after 0.01 sec\n",
      "search_closest_nodes_window: 86 matches generated for 2 df\n",
      "search_closest_nodes_window: len(no_match): 0\n",
      "86 matches for 2 warehouses\n"
     ]
    }
   ],
   "source": [
    "raw_wh_matches_window, no_match_wh = search_closest_nodes_window(\n",
    "    nodes, wh_df, 'name', stretch_lat, stretch_lng)\n",
    "print('%i matches for %i warehouses' % (\n",
    "    len(raw_wh_matches_window), len(wh_df)))\n",
    "assert len(no_match_wh) == 0\n",
    "# create wh_matches_window dataframe which maps warehouse names to node_ids\n",
    "wh_matches_window = pd.DataFrame(\n",
    "    raw_wh_matches_window, columns=['name', 'node_id'])\n",
    "# merge lat and lng of wh_df into wh_matches_window\n",
    "wh_matches_window = wh_matches_window.join(\n",
    "    wh_df.set_index('name'), on='name', rsuffix='_node')\n",
    "\n",
    "# join nodes df with matches\n",
    "wh_matched = wh_matches_window.join(nodes.drop(\n",
    "    columns=['gh']).set_index('id'), on='node_id', rsuffix='_node')\n",
    "assert len(scooter_matched) == len(matched)\n",
    "\n",
    "# calculate distances between scooters and nodes\n",
    "dist = wh_matched.rename(\n",
    "    columns={'lng': 'start_lng', 'lat': 'start_lat', \n",
    "             'lat_node': 'end_lat', 'lng_node': 'end_lng'}).apply(\n",
    "    lambda x: apply_hav(x), axis=1)\n",
    "wh_matched = wh_matched.assign(dist = dist)\n",
    "wh_matched = wh_matched.sort_values('dist')\n",
    "wh_nodes = wh_matched.groupby('name').first().reset_index()\n",
    "\n",
    "# # visually check if the matching worked\n",
    "# map_1 = KeplerGl(height=500, data={\n",
    "#     'data_1': wh_matched,\n",
    "#     'wh_nodes': wh_nodes,\n",
    "#     'nodes': nodes\n",
    "# }) # , config=config\n",
    "# map_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append warehouse nodes to scooter nodes\n",
    "scooter_wh_nodes = aggregate_df(scooter_nodes, wh_nodes.rename(columns={'name': 'scooter_id'}))\n",
    "\n",
    "# save matched scooters\n",
    "scooter_wh_nodes.to_csv(os.path.join(output_folder, \"scooter_wh_nodes.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all the distances between all scooters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scooter_wh_nodes = pd.read_csv(os.path.join(output_folder, \"scooter_wh_nodes.csv\"), index_col=0)\n",
    "\n",
    "f = open(os.path.join(dicts_path, 'where_nodes_dict.csv'), \"rb\")\n",
    "where_nodes_dict = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9fc90e12f604b76af818b610fabce47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=14), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "which_files = []\n",
    "for node in scooter_wh_nodes['node_id'].values:\n",
    "    which_files.append([node, where_nodes_dict[node]])\n",
    "which_files = pd.DataFrame(which_files, columns=['node_id', 'file_name'])\n",
    "which_files = which_files.sort_values('file_name')\n",
    "\n",
    "dist_dict = dict()\n",
    "for file_name in tqdm(np.sort(which_files.file_name.unique())):\n",
    "    node_ids = which_files[which_files['file_name'] == file_name]['node_id'].values\n",
    "\n",
    "    f = open(os.path.join(dicts_path, file_name), 'rb')\n",
    "    d = pickle.load(f)\n",
    "    f.close()\n",
    "\n",
    "    for nid in node_ids:\n",
    "        dist_dict[nid] = d[nid]\n",
    "\n",
    "ids_in_dict = []\n",
    "for k in dist_dict.keys():\n",
    "    ids_in_dict.append(k)\n",
    "ids_in_dict = np.sort(np.array(ids_in_dict))\n",
    "\n",
    "assert len(ids_in_dict) == len(np.sort(\n",
    "    scooter_wh_nodes['node_id'].unique()))\n",
    "assert len(np.setdiff1d(np.sort(\n",
    "    scooter_wh_nodes['node_id'].values), ids_in_dict)) == 0\n",
    "assert len(np.setdiff1d(ids_in_dict, np.sort(\n",
    "    scooter_wh_nodes['node_id'].values))) == 0\n",
    "\n",
    "f = open(os.path.join(dicts_path, 'dist_dict.csv'), \"wb\")\n",
    "pickle.dump(dist_dict, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the final scooters df\n",
    "scooters_final = pd.merge(pd.DataFrame(scooter_nodes.groupby('node_id')['scooter_id'].apply(list)).rename(\n",
    "             columns={'scooter_id': 'scooter_ids'}),\n",
    "         pd.DataFrame(scooter_nodes.groupby('node_id')['scooter_id'].count()).rename(\n",
    "             columns={'scooter_id': 'num_scooters'}),\n",
    "         left_index=True, right_index=True)\n",
    "scooters_final = pd.merge(scooters_final, scooter_nodes.groupby(\n",
    "    'node_id')[['lat_node', 'lng_node']].first(),\n",
    "         left_index=True, right_index=True).reset_index()\n",
    "\n",
    "assert len(scooters) == scooters_final['num_scooters'].sum()\n",
    "\n",
    "\n",
    "# create the wh scooters df\n",
    "wh_nodes = wh_nodes.assign(num_scooters = 0)\n",
    "wh_final = wh_nodes[\n",
    "    ['node_id', 'name', 'num_scooters',\n",
    "     'lat_node', 'lng_node']]\n",
    "\n",
    "assert len(wh_df) == len(wh_final)\n",
    "\n",
    "\n",
    "scooters_final.to_csv(os.path.join(output_folder, \"scooters_final.csv\"))\n",
    "wh_final.to_csv(os.path.join(output_folder, \"wh_final.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THIS CODE IS TESTED (= it worked once on my machine)\n",
    "## What you should have by now:\n",
    "\n",
    "- scooters_final.csv - Dataframe containing the scooters matched to the nodes with the columns: node_id, scooter_ids (SOMETIMES MULTIPLE SCOOTERS PER NODE), num_scooters (= number of scooters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
